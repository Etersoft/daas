1. Название виртуальной сети у каждого стенда должно быть своё (vagrant)
2. Конф. файл для gitlab-runner должен генерироваться
3. Настройка для docker (/etc/docker/...) должен генерироваться
4. /etc/hosts (для доступа к внутренним машинам)
или DNS внутри ВМ? посмотреть, что это https://github.com/aacebedo/dnsdock


5. Наличие модуля charbridge внутри ВМ (загрузка в /etc/modules и создание устройств)
6. На этапе разворачивания стенда, нужно залить или собрать образы для контрллеров и GUI
и залить из в локальный docker-регистр (vagrant?)

7. Имя gitlab-runner-а при регистрации в gitlab,  должно включать в себя (название проекта)
8. Подумать насчёт генерировать "скелет" для gitlab-ci.yml

9. Сейчас образы для сборки x64. Надо сделать и для i586 (докер образы)

10. Продумать как будет осуществляться запуск нескольких стендов.
Может стоит запускать несколько стендов и распределять pipeline между ними
(надо проверить все одинаковые runner-ы запускают задачи или только один из них)

11. Возможно надо делать несколько попыток устанавливать пакеты в Dockerfile (было пару раз, когда был недоступен ftp)

13. Стоит ли сделать отдельную поддержку запуска сервисов (возможно через serv, чтобы работало и в init и в systemd)
  run_services:
     - serv1
     - serv2
     - serv3

14. Продумать насчёт периодического запуска по cron "docker prune" для чистки ненужных или промежуточных образов
(пока что включил просто в gitlab-ci стадия cleanup).

17. daas admin hosts --confile project.yml    - генерирование hosts файла
18. daas init gitlab-ci --confile project.yml - генерирование скелета конф. файла для gitlab-ci
19. daas init [projectname] - генерирование шаблонного файла для проекта

22. Продумать скрипт архивирующий образ указанного узла (или всех). Со всеми Dockerfile и т.п.
Смысл в том, что потом можно было взять этот "срез" образов конкретного коммита и развернуть где-нибудь ещё.
Другой вариант, это архивировать только исходные данные и конф. файлы необходимые для поднятия "стенда".
Хотя формально это сейчас уже и так сохраняется в artefacts (gitlab-ci).
Попутно здесь можно сделать команду "запушить" в docker-registry текущий образы по специальными именами 
(например передавать скрипту COMMIT_SHA в качестве уникального префикса или постфикса).

23. Продумать линтер для конф. файла
daas check project.yml

24. Подумать насчёт объединить конфиги "vnc.d" и "logdb.d" для nginx в одну папку "project-name.d"

25. Продумать возможность использовать в файле проекта "переменные" типа {{project_name}},{{vstand_hostname}}, etc

26. Специальные контейнеры logdb и nginx в целом похожи на обчные узлы. Надо подумать об унификации их инициализации.
Т.е. чтобы они были как обычные узлы (входили в список project['nodes']), просто дополнительно конфигурировались
отдельными функциями (свой dockerfile, свои доп. файлы).

27. daas ssh config - генерирование config для ~/.ssh/config

28. Разделить Dockerfile-шаблоны (tpl) на базовую часть и дополнительные. Используя возможности "include"
в системе jinja2.  Тогда docker сможет использовать закешированные слои если у всех будут одинаковые части.

29. Если у узла skip_compose: yes  нужно ли тогда требовать наличие свойства 'ip'.
Похоже 'ip' можно сделать не обязательным и не включать тогда узел в сеть.
Тоже самое можно продумать на тему "обязательности" секции network 
(для проектов где только один узел или все skip_compose). Правда тогда непонятно зачем использовать daas

30. Продумать может сделать для 'nginx' возможность настраивать проброс прямо в файле проекта,
чтобы по нему генерировалась конфигурация для nginx.
Что-то типа
nginx:
   backends:
      myname:
      	 # на какой порт пробрасывать
         port: 4444
         # на какой host
         host: mybackend.host
         # по какому пути обрабатывать запросы в nginx
         locaction:  /mybackend/

      myname2:
         port: 4445
         host: mybackend2.host
         locaction:  /mybackend2/
         
При этом сейчас уже есть секция 'any' позволяющая указать готовые файлы подключаемые при старте nginx.
nginx:
  any:
    - myconf.location
    - myconf.upstream
    
Но удобство секции 'backends' в том, что конфигурация генерируется "сама". 
    

31. Подумать, может в настройках стенда создавать несколько runner-ов для сборки
(т.к. она может идти параллельно) и специальный runner для тестов - который будет выполнять 
только одно задание за раз. Тогда стадии которые можно собирать параллельно будут собираться параллельно.
А конфликтующие (последовательные стадии) можно будет настраивать на этот "спец. runner".
Потому-что сейчас есть только два runner-а:
- сборщик в docker
- просто runner на стенде (который и готовит контейнеры и запускает тесты и всё остальное)

33. Команда для разворачивания (на подумать):
daas gitlab create - создание и запуск gitlab-сверера в docker
daas vstand init - подготовка стендовой машины 
(установка vargant в docker, установка ansible, подготовка ВМ, создание пользователя и выдача нужных прав).
Подразумевается разворачивание на "новенькой" пустой машине с ALT.

34. Нужно ли дать возможность в настройках сети добавлять свои дополнительные hosts
network:
  extra_hosts:
    - "myextnode1 myext: 127.0.0.1"
    - "myextnode2 myext2: 192.168.0.1"

35. Подумать насчёт всё-таки переименовать 'image:' в 'template:' в файле проекта

36. Подумать насчёт генерировать пусты файлы указанные как env_file-ы (если они не существуют),
чтобы docker-compose в любом случае запускался, а не ругался на их отсутсвие.

37. daas log get buildnum [gitlab-addr]
Вообщем команда на получение логов сборки (artifacts)

39 Всякие способы чистки
docker images | grep -e '[23] weeks ago' | grep -v regis | awk '{print $1}' | xargs docker image rm

# Самый крутой! Удаляет почти всё что можно..
docker system prune
